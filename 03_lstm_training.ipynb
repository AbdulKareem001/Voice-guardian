{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bbc42e0-2441-4f37-8d69-f4551771c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9d069a-1037-4dfa-b5e5-7c84a0766ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_DIR = \"E:/voiceguardian/data/features\"\n",
    "emotion_map = {\n",
    "    \"01\": \"neutral\", \"02\": \"calm\", \"03\": \"happy\", \"04\": \"sad\",\n",
    "    \"05\": \"angry\", \"06\": \"fearful\", \"07\": \"disgust\", \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "X, y = [], []\n",
    "for file in os.listdir(FEATURE_DIR):\n",
    "    if file.endswith(\".npy\"):\n",
    "        mfcc = np.load(os.path.join(FEATURE_DIR, file))\n",
    "        if mfcc.shape[0] >= 60:  # Ensure minimum length\n",
    "            mfcc = mfcc[:60]  # Truncate\n",
    "            X.append(mfcc)\n",
    "            label = emotion_map.get(file.split(\"-\")[2], \"unknown\")\n",
    "            y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a02aff4c-603d-45d0-bff6-62de81ea0c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_cat = to_categorical(y_encoded)\n",
    "\n",
    "X = np.array(X)  # Shape: (samples, timesteps, features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "843f69f8-e198-4345-b914-60f7e5d291bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape          </span>┃<span style=\"font-weight: bold\">      Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│ masking_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├───────────────────────────────┼───────────────────────┼──────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">86,528</span> │\n",
       "├───────────────────────────────┼───────────────────────┼──────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├───────────────────────────────┼───────────────────────┼──────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├───────────────────────────────┼───────────────────────┼──────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├───────────────────────────────┼───────────────────────┼──────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "└───────────────────────────────┴───────────────────────┴──────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m     Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│ masking_1 (\u001b[38;5;33mMasking\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │            \u001b[38;5;34m0\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────┼──────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m86,528\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────┼──────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │            \u001b[38;5;34m0\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────┼──────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │        \u001b[38;5;34m8,256\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────┼──────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │            \u001b[38;5;34m0\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────┼──────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)             │          \u001b[38;5;34m520\u001b[0m │\n",
       "└───────────────────────────────┴───────────────────────┴──────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">95,304</span> (372.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m95,304\u001b[0m (372.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">95,304</span> (372.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m95,304\u001b[0m (372.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(60, 40)),                 # 👈 Correct way to specify input\n",
    "    Masking(mask_value=0.),\n",
    "    LSTM(128, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(y_cat.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b61368-02fc-4c2b-b746-2cef9d2fb8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 205ms/step - accuracy: 0.1137 - loss: 2.2044 - val_accuracy: 0.2432 - val_loss: 1.9994\n",
      "Epoch 2/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 154ms/step - accuracy: 0.2197 - loss: 2.0227 - val_accuracy: 0.3018 - val_loss: 1.9090\n",
      "Epoch 3/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - accuracy: 0.2493 - loss: 1.9460 - val_accuracy: 0.3108 - val_loss: 1.8564\n",
      "Epoch 4/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.2578 - loss: 1.8922 - val_accuracy: 0.3063 - val_loss: 1.7851\n",
      "Epoch 5/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.2953 - loss: 1.8248 - val_accuracy: 0.3333 - val_loss: 1.7449\n",
      "Epoch 6/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - accuracy: 0.3344 - loss: 1.7744 - val_accuracy: 0.3423 - val_loss: 1.6923\n",
      "Epoch 7/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 166ms/step - accuracy: 0.3859 - loss: 1.6584 - val_accuracy: 0.3649 - val_loss: 1.6765\n",
      "Epoch 8/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.3865 - loss: 1.6670 - val_accuracy: 0.3784 - val_loss: 1.6617\n",
      "Epoch 9/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.3859 - loss: 1.6626 - val_accuracy: 0.3649 - val_loss: 1.6276\n",
      "Epoch 10/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 0.3970 - loss: 1.5886 - val_accuracy: 0.4099 - val_loss: 1.6133\n",
      "Epoch 11/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - accuracy: 0.4654 - loss: 1.5143 - val_accuracy: 0.3964 - val_loss: 1.5829\n",
      "Epoch 12/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.4880 - loss: 1.4100 - val_accuracy: 0.3964 - val_loss: 1.6136\n",
      "Epoch 13/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.4866 - loss: 1.4102 - val_accuracy: 0.3964 - val_loss: 1.6179\n",
      "Epoch 14/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.4861 - loss: 1.4219 - val_accuracy: 0.4189 - val_loss: 1.5924\n",
      "Epoch 15/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - accuracy: 0.5310 - loss: 1.3207 - val_accuracy: 0.4414 - val_loss: 1.5704\n",
      "Epoch 16/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.5402 - loss: 1.2612 - val_accuracy: 0.4189 - val_loss: 1.5702\n",
      "Epoch 17/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - accuracy: 0.5501 - loss: 1.2840 - val_accuracy: 0.4459 - val_loss: 1.5489\n",
      "Epoch 18/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.5596 - loss: 1.2070 - val_accuracy: 0.4234 - val_loss: 1.5564\n",
      "Epoch 19/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.5606 - loss: 1.2031 - val_accuracy: 0.4550 - val_loss: 1.5249\n",
      "Epoch 20/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - accuracy: 0.5870 - loss: 1.1820 - val_accuracy: 0.4279 - val_loss: 1.5649\n",
      "Epoch 21/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - accuracy: 0.5739 - loss: 1.1430 - val_accuracy: 0.4685 - val_loss: 1.5367\n",
      "Epoch 22/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - accuracy: 0.5798 - loss: 1.1554 - val_accuracy: 0.4459 - val_loss: 1.5450\n",
      "Epoch 23/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - accuracy: 0.5862 - loss: 1.1248 - val_accuracy: 0.4505 - val_loss: 1.5242\n",
      "Epoch 24/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - accuracy: 0.6265 - loss: 1.0364 - val_accuracy: 0.4099 - val_loss: 1.5795\n",
      "Epoch 25/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - accuracy: 0.5936 - loss: 1.1030 - val_accuracy: 0.4054 - val_loss: 1.5936\n",
      "Epoch 26/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 0.6178 - loss: 1.0715 - val_accuracy: 0.4234 - val_loss: 1.5734\n",
      "Epoch 27/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - accuracy: 0.6348 - loss: 1.0237 - val_accuracy: 0.4279 - val_loss: 1.6366\n",
      "Epoch 28/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - accuracy: 0.6827 - loss: 0.9315 - val_accuracy: 0.4550 - val_loss: 1.5343\n",
      "Epoch 29/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - accuracy: 0.6541 - loss: 0.9763 - val_accuracy: 0.4595 - val_loss: 1.5444\n",
      "Epoch 30/30\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 175ms/step - accuracy: 0.6845 - loss: 0.8855 - val_accuracy: 0.4369 - val_loss: 1.5604\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32,\n",
    "                    validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6607c89-0a1f-405b-a17a-be0d7d3f7db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.3697 - loss: 2.3214\n",
      "✅ Test Accuracy: 0.40\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"✅ Test Accuracy: {acc:.2f}\")\n",
    "\n",
    "model.save(\"E:/voiceguardian/models/emotion_lstm_model.keras\")\n",
    "np.save(\"E:/voiceguardian/models/label_classes.npy\", le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6731908-2706-408e-a262-94daf9339e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\voiceguardian\\voice_env\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 9 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c24f9-950f-4f88-b696-4857ee60ea90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
